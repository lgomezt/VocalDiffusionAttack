{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9daccbc5",
   "metadata": {},
   "source": [
    "# Validate Watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36cd3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import torch.nn.functional as F\n",
    "from audioseal import AudioSeal\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d00967",
   "metadata": {},
   "outputs": [],
   "source": [
    "watermarked_path = \"../Dataset/Watermarked Audio\"\n",
    "unwatermarked_path = \"../Dataset/Unwatermarked Audio\"\n",
    "transcription_path = '../Dataset/Transcriptions/transcriptions_complete.csv'\n",
    "results_path = '../Dataset/Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4012ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# 1. Import the watermark detector\n",
    "detector = AudioSeal.load_detector(\"audioseal_detector_16bits\")\n",
    "\n",
    "# 2. Import the model for transcription\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device)\n",
    "\n",
    "# Whisper and AudioSeal expect a sample rate of 16khz\n",
    "target_sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297dfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all filepaths\n",
    "unwatermarked_files = os.listdir(unwatermarked_path)\n",
    "unwatermarked_files = [i for i in unwatermarked_files if i[-4:] == \".mp3\"]\n",
    "unwatermarked_files = [i for i in unwatermarked_files if \"audioseal\" in i]\n",
    "\n",
    "watermarked_files = os.listdir(watermarked_path)\n",
    "watermarked_files = [i for i in watermarked_files if i[-4:] == \".mp3\"]\n",
    "watermarked_files = [i for i in watermarked_files if \"audioseal\" in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e7d4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to extract the ID from the filename\n",
    "def extract_id(filename):\n",
    "    match = re.search(r'common_voice_en_(\\d+)', filename)\n",
    "    return match.group(1) if match else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "206bbc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audios to evaluate: 14,124\n"
     ]
    }
   ],
   "source": [
    "# Build dicts by ID\n",
    "un_dict = {extract_id(f): f for f in unwatermarked_files}\n",
    "w_dict = {extract_id(f): f for f in watermarked_files}\n",
    "\n",
    "# Find common IDs and build a dict with (un, w) tuples\n",
    "matched = {id_: (un_dict[id_], w_dict[id_]) for id_ in un_dict.keys() & w_dict.keys()}\n",
    "\n",
    "print(f\"Audios to evaluate: {len(matched):0,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962b2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining clips 0 (0.0%)\n",
      "Last file number:  16\n"
     ]
    }
   ],
   "source": [
    "# Find IDs already processed\n",
    "processed_ids = []\n",
    "last_file_num = 0\n",
    "for file in os.listdir(results_path):\n",
    "    file_path = os.path.join(results_path, file)\n",
    "    if file.startswith(\"results_watermark_prob_\"):\n",
    "        file_num = re.search(r'results_watermark_prob_(\\d+).csv', file).group(1)\n",
    "        last_file_num = np.max([int(file_num), last_file_num])\n",
    "        temp = pd.read_csv(file_path, usecols=[\"id\"])\n",
    "        processed_ids.extend(temp[\"id\"].astype(str).tolist())\n",
    "\n",
    "remaining_clips = list(matched.keys() - set(processed_ids))\n",
    "print(f\"Remaining clips {len(remaining_clips):0,.0f} ({len(remaining_clips)/len(matched.keys()):0.1%})\")\n",
    "print(\"Last file number: \", last_file_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84297319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "for n, i in tqdm(enumerate(remaining_clips), total=len(remaining_clips)):\n",
    "    \n",
    "    un, w = matched[i]\n",
    "    # Load the unwatermarked audio file\n",
    "    un_path = os.path.join(unwatermarked_path, un)\n",
    "    un_wav, sr = librosa.load(un_path, sr=target_sr)\n",
    "    # Convert to float32 tensor for PyTorch\n",
    "    un_wav_tensor = torch.tensor(un_wav, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "    # Detect the watermark\n",
    "    prob, _ = detector.detect_watermark(un_wav_tensor, sr)\n",
    "    # Save result\n",
    "    all_results.append([i, prob])\n",
    "\n",
    "    # Save results every 1000 items or at the end\n",
    "    if (n % 1000 == 0 and n > 0) or (n == len(remaining_clips) - 1):\n",
    "        last_file_num += 1\n",
    "        results_df = pd.DataFrame(all_results, columns=[\"id\", \"prob_w\"])\n",
    "        output_filename = f\"results_watermark_prob_{last_file_num}.csv\"\n",
    "        results_df.to_csv(os.path.join(results_path, output_filename), index=False)\n",
    "        all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168967d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14124, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results = pd.DataFrame()\n",
    "for file in os.listdir(results_path):\n",
    "    file_path = os.path.join(results_path, file)\n",
    "    if file.startswith(\"results_watermark_prob_\"):\n",
    "        temp = pd.read_csv(file_path)\n",
    "        all_results = pd.concat([all_results, temp])\n",
    "all_results = all_results.drop_duplicates(subset=[\"id\"])\n",
    "all_results = all_results.reset_index(drop=True)\n",
    "all_results.to_csv(os.path.join(results_path, \"all_results_watermark_prob.csv\"), index=False)\n",
    "all_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd9f964d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1412400.00%\n",
       "mean           0.25%\n",
       "std            0.82%\n",
       "min            0.00%\n",
       "25%            0.00%\n",
       "50%            0.00%\n",
       "75%            0.17%\n",
       "max           28.43%\n",
       "Name: prob_w, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results[\"prob_w\"].describe().apply(lambda x: f\"{x:0.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VocalDiffusionAttack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
